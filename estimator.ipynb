{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb178e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# Training Parameters\n",
    "params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'training_steps': 20000,\n",
    "    'batch_size': 128,\n",
    "    'display_step': 100,\n",
    "\n",
    "    # Network Parameters\n",
    "    'num_input': 28,  # MNIST data input (img shape: 28*28)\n",
    "    'timesteps': 28,  # timesteps\n",
    "    'num_hidden': 128,  # hidden layer num of features\n",
    "    'num_classes': 10  # MNIST total classes (0-9 digits)\n",
    "}\n",
    "\n",
    "def estimator_spec(logits, labels, mode, params):\n",
    "    loss, train_op, predictions = None, None, None\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        onehot_labels = tf.one_hot(labels, params['num_classes'], 1, 0)\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=onehot_labels))\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=params['learning_rate'])\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {'prediction': tf.argmax(logits, 1),\n",
    "                       'prob': tf.nn.softmax(logits)}\n",
    "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=tf.argmax(logits, 1))}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    '''\n",
    "    To classify images using a recurrent neural network, we consider every image\n",
    "    row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\n",
    "    handle 28 sequences of 28 steps for every sample.\n",
    "    '''\n",
    "\n",
    "    x = tf.reshape(features['x'], [-1, params['timesteps'], params['num_input']])\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, params['timesteps'], 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(params['num_hidden'], forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    # outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    logits = tf.layers.dense(states[-1], units=params['num_classes'])\n",
    "    return estimator_spec(logits=logits, labels=labels, mode=mode, params=params)\n",
    "\n",
    "def main(args = None):\n",
    "    run_config = tf.estimator.RunConfig()\n",
    "    # run_config = run_config.replace(**{'save_checkpoints_steps': 100, 'keep_checkpoint_max': 20})\n",
    "    classifier = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                                        model_dir='drive/tmp/checkpoint',\n",
    "                                        params=params,\n",
    "                                        config=run_config)\n",
    "\n",
    "    # make data\n",
    "    mnist = tf.contrib.learn.datasets.DATASETS['mnist']('/tmp/mnist')\n",
    "    \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {'x': mnist.train.images},\n",
    "        y = mnist.train.labels.astype(np.int32),\n",
    "        batch_size=params['batch_size'],\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'x': mnist.train.images},\n",
    "        y=mnist.train.labels.astype(np.int32),\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "\n",
    "    # classifier.train(input_fn=train_input_fn, steps=params['training_steps'], hooks=[])\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=params['training_steps'])\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\n",
    "    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\n",
    "    score = classifier.evaluate(eval_input_fn, steps=1)\n",
    "    print(score)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main(None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
