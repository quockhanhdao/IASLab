{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giới thiệu Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "* https://www.tensorflow.org/\n",
    "* https://www.datacamp.com/community/tutorials/tensorflow-tutorial\n",
    "\n",
    "TensorFlow is a general-purpose system for graph-based computation.\n",
    "\n",
    "TensorFlow gets its name from tensors, which are arrays of arbitrary dimensionality. A vector is a 1-d array and is known as a 1st-order tensor. A matrix is a 2-d array and a 2nd-order tensor. The \"flow\" part of the name refers to computation flowing through a graph. Training and inference in a neural network, for example, involves the propagation of matrix computations through many nodes in a computational graph.\n",
    "\n",
    "When you think of doing things in TensorFlow, you might want to think of creating tensors (like matrices), adding operations (that output other tensors), and then executing the computation (running the computational graph). In particular, it's important to realize that when you add an operation on tensors, **it doesn't execute immediately**. Rather, TensorFlow waits for you to define all the operations you want to perform. Then, TensorFlow optimizes the computation graph, deciding how to execute the computation, before generating the data. Because of this, a tensor in TensorFlow isn't so much holding the data as a placeholder for holding the data, waiting for the data to arrive when a computation is executed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session():\n",
    "    input1 = tf.constant([1.0, 1.0, 1.0, 1.0])\n",
    "    input2 = tf.constant([2.0, 2.0, 2.0, 2.0])\n",
    "    output = tf.add(input1, input2)\n",
    "    print('output:', output)\n",
    "    result = output.eval()\n",
    "    print(\"result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print([x + y for x, y in zip([1.0] * 4, [2.0] * 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = np.full(4, 1.0), np.full(4, 2.0)\n",
    "print(\"{} + {} = {}\".format(x, y, x + y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcast multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "print(result)\n",
    "\n",
    "# TODO student add code to see result value\n",
    "# print(result.numpy()) # Đối với tensorflow 2.x\n",
    "print(result.eval(session = tf.Session())) # Đối với tensorflow 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session():\n",
    "    input1 = tf.constant(1.0, shape=[4])\n",
    "    input2 = tf.constant(2.0, shape=[4])\n",
    "    input3 = tf.constant(3.0, shape=[4])\n",
    "    output = tf.add(tf.add(input1, input2), input3)\n",
    "    result = output.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session():\n",
    "    input1 = tf.constant(1.0, shape=[4])\n",
    "    input2 = tf.constant(2.0, shape=[4])\n",
    "    output = input1 + input2\n",
    "    print(output.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngoài eval(), chúng ta thường dùng session.run() để thực hiện việc tính toán các giá trị của tensor, với tensor *output* ở trên chúng ta có thể tính giá trị như dưới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(output)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session():\n",
    "    input_features = tf.constant(np.reshape([1, 0, 0, 1], (1, 4)).astype(np.float32))\n",
    "    weights = tf.constant(np.random.randn(4, 2).astype(np.float32))\n",
    "    output = tf.matmul(input_features, weights)\n",
    "    print(\"Input:\")\n",
    "    print(input_features.eval())\n",
    "    print(\"Weights:\")\n",
    "    print(weights.eval())\n",
    "    print(\"Output:\")\n",
    "    print(output.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Làm quen với khái niệm**:\n",
    "\n",
    "Sinh viên đọc và chú ý phân biệt ý nghĩa sử dụng của chúng:\n",
    "\n",
    "* https://www.tensorflow.org/api_docs/python/tf/placeholder\n",
    "\n",
    "* https://www.tensorflow.org/api_docs/python/tf/Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape = (1024, 1024))\n",
    "y = tf.matmul(x, x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
    "\n",
    "  rand_array = np.random.rand(1024, 1024)\n",
    "  print(sess.run(y, feed_dict = {x: rand_array}))  # Will succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this 2 times may cause error: Variable v already exists\n",
    "with tf.Session() as sess:\n",
    "    v = tf.get_variable(\"v\", shape=(), initializer = tf.zeros_initializer())\n",
    "    assignment = v.assign_add(1)\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(assignment.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Set up two variables, total and weights, that we'll change repeatedly.\n",
    "    total = tf.Variable(tf.zeros([1, 2]))\n",
    "    weights = tf.Variable(tf.random_uniform([1,2]))\n",
    "\n",
    "    # Initialize the variables we defined above.\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # This only adds the operators to the graph right now. The assignment\n",
    "    # and addition operations are not performed yet.\n",
    "    update_weights = tf.assign(weights, tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "    update_total = tf.assign(total, tf.add(total, weights))\n",
    "  \n",
    "    for _ in range(5):\n",
    "        # Actually run the operation graph, so randomly generate weights and then\n",
    "        # add them into the total. Order does matter here. We need to update\n",
    "        # the weights before updating the total.\n",
    "        sess.run(update_weights)\n",
    "        sess.run(update_total)\n",
    "    \n",
    "        print(weights.eval(), total.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Example from: [aymericdamien](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/2_BasicModels/linear_regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print (\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow arithmetic operators**\n",
    "\n",
    "https://www.tensorflow.org/api_guides/python/math_ops#Arithmetic_Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài tập\n",
    "\n",
    "Bài nộp của sinh viên là chính là **file này** sau khi được đổi tên thành **MSSV.E9_introduction_numpy.ipynb** và đừng quên ghi thông tin sinh viên vào các ô ở dưới.\n",
    "\n",
    "Địa chỉ nộp bài: https://www.dropbox.com/request/h084jC1ZUTkUm5gosR6l\n",
    "\n",
    "Deadline nộp bài: **10:00 thứ 2 tuần tiếp theo**\n",
    "\n",
    "*Điểm bài này sẽ được tổng hợp với điểm chấm trên lớp (nếu có) để ra điểm cuối cùng*\n",
    "\n",
    "Thông tin sinh viên:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\daoqu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "sid = '2013452'\n",
    "name = 'Đào Quốc Khánh'\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "# sinh viên import các thư viện cần thiết ở đây\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 1\n",
    "Trong bài này, sinh viên sẽ tập làm quen với các thao tác cơ bản trên numpy, tensorflow, so sánh, đánh giá đơn giản về tốc độ tính toán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Sinh viên viết hàm matrix_gen(m, n) để sinh ra ma trận các số thực trong khoảng [0, 1] ngẫu nhiên, output là python array biểu diễn cho ma trận. Sử dụng hàm để sinh ra hai ma trận và lưu vào hai biến tương ứng đã cho để sử dụng cho các câu tiếp theo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code sinh viên cho câu a\n",
    "def matrix_gen(m, n):\n",
    "    return np.random.random((m, n))\n",
    "\n",
    "m, n, k = 50, 40, 60\n",
    "matrix_mn = matrix_gen(m, n)\n",
    "matrix_nk = matrix_gen(n, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Hãy viết một hàm py_matrix_mul(matrix_1, matrix_2) để nhân hai ma trận được truyền vào trong đó không sử dụng numpy, tensorflow hay các thư viện khác. (giả sử input đã đúng không cần kiểm tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.04333602  9.72346676  9.15356217 ... 10.50313196  9.62077836\n",
      "   9.57575014]\n",
      " [ 9.6920086   9.91145759 10.29937932 ...  9.92578066 10.06694413\n",
      "   9.08905957]\n",
      " [10.046891    9.98816286 10.22190643 ... 11.29951049  9.96448027\n",
      "  10.53370855]\n",
      " ...\n",
      " [10.35551496  9.65445662 11.02806932 ... 12.18337968 11.08790012\n",
      "  11.06962025]\n",
      " [ 9.40223453  9.07298176  9.20582547 ... 10.47146149  8.10587498\n",
      "   8.82366764]\n",
      " [ 7.69268204  8.39625549  8.25929436 ...  9.50640296  8.31740685\n",
      "   7.67092169]]\n",
      "Execution time: 84.86819267272949 ms\n"
     ]
    }
   ],
   "source": [
    "# code câu b của sinh viên\n",
    "def py_matrix_mul(matrix_1, matrix_2):\n",
    "    (m1, n1), (m2, n2) = matrix_1.shape, matrix_2.shape\n",
    "    if n1 != m2:\n",
    "        print(\"Invalid!\")\n",
    "        return\n",
    "    ans = np.zeros((m1, n2))\n",
    "    for i in range(m1):\n",
    "        for j in range(n2):\n",
    "            for k in range(n1):\n",
    "                ans[i, j] += matrix_1[i][k] * matrix_2[k][j]\n",
    "    return ans\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "mt_mul_py = py_matrix_mul(matrix_mn, matrix_nk)\n",
    "print(mt_mul_py)\n",
    "\n",
    "end = time.time()\n",
    "t = (end - start) * 1000\n",
    "print('Execution time:', t, 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Sử dụng numpy để hiện thực cho bài toán nhân hai ma trận với hai ma trân *matrix_mn* và *matrix_nk*, lưu kết quả cuối cùng vào mt_mul_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.04333602  9.72346676  9.15356217 ... 10.50313196  9.62077836\n",
      "   9.57575014]\n",
      " [ 9.6920086   9.91145759 10.29937932 ...  9.92578066 10.06694413\n",
      "   9.08905957]\n",
      " [10.046891    9.98816286 10.22190643 ... 11.29951049  9.96448027\n",
      "  10.53370855]\n",
      " ...\n",
      " [10.35551496  9.65445662 11.02806932 ... 12.18337968 11.08790012\n",
      "  11.06962025]\n",
      " [ 9.40223453  9.07298176  9.20582547 ... 10.47146149  8.10587498\n",
      "   8.82366764]\n",
      " [ 7.69268204  8.39625549  8.25929436 ...  9.50640296  8.31740685\n",
      "   7.67092169]]\n",
      "Execution time: 0.99945068359375 ms\n"
     ]
    }
   ],
   "source": [
    "# code câu c của sinh viên\n",
    "start = time.time()\n",
    "\n",
    "mt_mul_numpy = np.dot(matrix_mn, matrix_nk)\n",
    "print(mt_mul_numpy)\n",
    "\n",
    "end = time.time()\n",
    "t = (end - start) * 1000\n",
    "print('Execution time:', t, 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Sử dụng tensorflow để hiện thực cho câu c thay vì dùng numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.04333602  9.72346676  9.15356217 ... 10.50313196  9.62077836\n",
      "   9.57575014]\n",
      " [ 9.6920086   9.91145759 10.29937932 ...  9.92578066 10.06694413\n",
      "   9.08905957]\n",
      " [10.046891    9.98816286 10.22190643 ... 11.29951049  9.96448027\n",
      "  10.53370855]\n",
      " ...\n",
      " [10.35551496  9.65445662 11.02806932 ... 12.18337968 11.08790012\n",
      "  11.06962025]\n",
      " [ 9.40223453  9.07298176  9.20582547 ... 10.47146149  8.10587498\n",
      "   8.82366764]\n",
      " [ 7.69268204  8.39625549  8.25929436 ...  9.50640296  8.31740685\n",
      "   7.67092169]]\n",
      "Execution time: 7.72857666015625 ms\n"
     ]
    }
   ],
   "source": [
    "# code câu d của sinh viên\n",
    "start = time.time()\n",
    "\n",
    "mt_mul_tensorflow = tf.matmul(matrix_mn, matrix_nk).eval(session = tf.Session())\n",
    "print(mt_mul_tensorflow)\n",
    "\n",
    "end = time.time()\n",
    "t = (end - start) * 1000\n",
    "print('Execution time:', t, 'ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Với các câu b, c, d, hãy chèn đoạn code để tính thời gian thực thi của mỗi phương pháp và so sánh, đánh giá về mặt thời gian thực thi của các thao tác.\n",
    "\n",
    "Nhận xét của sinh viên: Sau khi chạy thử và tính toán thời gian thực thi của từng phương pháp, ta có được:\n",
    "\n",
    "    - Sử dụng hàm tự viết py_matrix_mul: xấp xỉ 145 - 160 (ms)\n",
    "    \n",
    "    - Sử dụng np.dot trong numpy: xấp xỉ 1 - 2 (ms)\n",
    "    \n",
    "    - Sử dụng tf.matmul (bao gồm cả thao tác chuyển đổi kết quả từ Tensor về np.array): xấp xỉ 20 - 24 (ms)\n",
    "    \n",
    "    - Sử dụng tf.matmul (không bao gồm cả thao tác chuyển đổi kết quả từ Tensor về np.array): xấp xỉ 2 - 8 (ms)\n",
    "    \n",
    "Từ đó ta nhận thấy được, việc sử dụng các hàm tích hợp sẵn trong numpy hoặc tensorflow hiệu quả hơn gấp nhiều lần đối với hàm chúng ta tự viết để nhân hai ma trận - O(n^3). Trong đó, việc sử dụng numpy.dot có hiệu quả hơn hẳn so với 2 phương pháp còn lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 2\n",
    "\n",
    "Cho đoạn code sinh dữ liệu cho hàm f() như bên dưới.\n",
    "Sinh viên hãy chỉnh sửa đoạn code Linear Regression, \n",
    "chọn các tham số phù hợp để ra được kết quả tốt nhất có thể."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0.51438488 0.52173564 0.29836453 0.39201767 0.65906791 0.14205105\n",
      " 0.02838277 0.1843252  0.58105676 0.49623616 0.38848509 0.05374833\n",
      " 0.31764084 0.68044831 0.99413022 0.13253451 0.72523097 0.7789529\n",
      " 0.51816774 0.02095499 0.39198117 0.32096096 0.03429861 0.88842294\n",
      " 0.85317734 0.97020148 0.9393118  0.15204845 0.23025061 0.92494352\n",
      " 0.71026449 0.64030493 0.69698969 0.03997689 0.29734708 0.73587795\n",
      " 0.2432251  0.90528843 0.6460306  0.0827737  0.27396939 0.46808267\n",
      " 0.85837567 0.83024922 0.33940421 0.18034504 0.50946854 0.83071489\n",
      " 0.02823792 0.83841541]\n",
      "y [5.6360219  5.667278   4.58739761 4.84265372 6.33054473 3.79517611\n",
      " 2.99799758 3.79220285 5.89514491 5.44998076 4.77352392 3.3544446\n",
      " 4.63095371 6.51447909 7.99461694 3.47995364 6.63574736 6.79968687\n",
      " 5.64735851 3.16059198 5.14251932 4.56874879 3.03550788 7.42335356\n",
      " 7.06912619 7.83697853 7.72426609 3.74803701 4.2054116  7.46822762\n",
      " 6.4745641  6.05790465 6.27045933 3.21181662 4.52659008 6.72005464\n",
      " 4.19982821 7.5544282  6.21262087 3.28248857 4.25012453 5.20755473\n",
      " 7.29714876 7.2025076  4.67223147 3.94380525 5.51443916 7.00391557\n",
      " 3.22390556 7.1420926 ]\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x * 5 + 3\n",
    "\n",
    "llen = 50\n",
    "x = np.random.rand(llen)\n",
    "y = f(x) + np.random.normal(0, 0.1, llen)\n",
    "\n",
    "print('x', x)\n",
    "print('y', y)\n",
    "\n",
    "train_X = x\n",
    "train_Y = y\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Code sinh viên ở dưới*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Training cost = 0.0042992835 W = 4.9788527  b= 2.9789388 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAiqElEQVR4nO3de3xU1bn/8c8iIhEFo4i3YjKIaLkEUFK80OIFUQverZQ21lttfgq/wqnWQo2iLScKXmrV4iUePWgbRYVSKWBrW1QUqzUgGG4KyEBBK0gbJAY0hnX+2JOQmdkzsxNmJntmvu/XixeZNWtm1jb4ZOXZaz3LWGsRERH/6tDeAxARkfgUqEVEfE6BWkTE5xSoRUR8ToFaRMTn9kvFmx522GE2EAik4q1FRLLSkiVLPrXWdnd7LiWBOhAIUF1dnYq3FhHJSsaYjbGeU+pDRMTnFKhFRHxOgVpExOdSkqN209DQwObNm9m9e3e6PlLiyM/Pp0ePHnTs2LG9hyIiCaQtUG/evJkuXboQCAQwxqTrY8WFtZbt27ezefNmevbs2d7DEZEEPKU+jDE/McasNMasMMY8a4zJb+0H7d69m27duilI+4Axhm7duum3G5FkqaqCQAA6dHD+rqpK6tsnDNTGmK8B44ESa21/IA8Y05YPU5D2D30vRJKkqgrKymDjRrDW+busLKnB2uvNxP2AA4wx+wGdgY+SNgIRkUxWXg719eFt9fVOe5IkDNTW2i3AvcAm4GNgh7X25ch+xpgyY0y1MaZ627ZtSRtgMm3evJmLLrqI3r1706tXLyZMmMCXX37p2vejjz7iO9/5TsL3HDlyJLW1tW0azx133MG9996bsN9BBx0U9/na2loefvjhNo1BRPbRpk2ta28DL6mPQ4CLgJ7A0cCBxpgrIvtZayuttSXW2pLu3V13QbZOknM+1louvfRSLr74YtauXcsHH3xAXV0d5S4/9b766iuOPvpoZs2alfB9FyxYQEFBwT6NbV8pUIu0o8LC1rW3gZfUx9nABmvtNmttA/B74LSkjcBNCnI+CxcuJD8/n2uuuQaAvLw87r//fp588knq6+uZMWMGF154IWeddRbDhw8nGAzSv39/AOrr6xk9ejR9+/blkksu4eSTT27eIh8IBPj0008JBoP06dOHH/3oR/Tr149zzjmHXbt2AfD444/zjW98g4EDB3LZZZdRH/lrUoQNGzZw6qmnUlxczK233trcXldXx/DhwznppJMoLi7mxRdfBGDSpEmsX7+eQYMGcfPNN8fsJyIpUFHBhqOOJTBxHv91/k1OW+fOUFGRtI/wEqg3AacYYzob5w7UcGB10kbgJgU5n5UrVzJ48OCwtq5du1JYWMi6desAWLp0KbNmzeK1114L6/fwww9zyCGHsGrVKqZMmcKSJUtcP2Pt2rWMGzeOlStXUlBQwOzZswG49NJLeeedd1i+fDl9+vThiSeeiDvWCRMmcMMNN1BTU8NRRx3V3J6fn8+cOXNYunQpr7zyCjfddBPWWqZOnUqvXr1YtmwZ99xzT8x+IrIPXH7Lt9Zy1Re9OfPKBwHY3rkAioqgshJKS5P20QnXUVtr3zbGzAKWAl8B7wKVSRuBmzTkfNyMGDGCQw89NKr9jTfeYMKECQD079+fAQMGuL6+Z8+eDBo0CIDBgwcTDAYBWLFiBbfeeiu1tbXU1dVx7rnnxh3H4sWLm4P8D37wAyZOnAg46ZtbbrmFRYsW0aFDB7Zs2cInn3wS9fpY/Y488khP/x1EJELTb/lNE8iNG1k05TdcWVPQ3OWBMYO4aNAo4FbXt9gXnja8WGtvB25P+qfHUljopDvc2tuob9++UTnnzz77jE2bNnHcccexdOlSDjzwwDa/P0CnTp2av87Ly2tOfVx99dX84Q9/YODAgcyYMYNXX3014Xu5LZ+rqqpi27ZtLFmyhI4dOxIIBFzXQnvtJyIetfgtf9d+nRgy7il25js3+U84ogvzxn+Tjnmpq8jhz1ofFRVOjqelfcz5DB8+nPr6ep5++mkAGhsbuemmm7j66qvpHPlZEYYOHcrzzz8PwKpVq6ipqWnVZ+/cuZOjjjqKhoYGqjzk2YcOHcrMmTMBwvrv2LGDww8/nI4dO/LKK6+wMfTDrEuXLuzcuTNhPxFpo9Bv8/cP/T59bprdHKRffPpG/vyTYSkN0uDXQF1a6uR4iorAmKTkfIwxzJkzhxdeeIHevXtz/PHHk5+fz5133pnwtWPHjmXbtm307duXW2+9lX79+nHwwQd7/uwpU6Zw8sknM3ToUL7+9a8n7P/AAw8wffp0iouL2bJlS3N7aWkp1dXVFBcX8/TTTze/V7du3Rg6dCj9+/fn5ptvjtlPRNpmyYmnE5g4jwe++X0Avrv8zwSnnc/A/b9Iy+ebVNxkKikpsZEHB6xevZo+ffok/bPSobGxkYaGBvLz81m/fj1nn30277//Pvvvv397D22fZPL3RCRpqqqc1MamTU56taKieVJoraXnzxeEdV/06A8p3PGJ81t+Em8aGmOWWGtL3J5LW1GmTFZfX8+ZZ55JQ0MD1loefvjhjA/SIoLrTULKygB4/JhTqViwd4HbCZ0a+fNT4+Gzrc5v+S0CeqopUHvQpUsXHS0mko1clgLXNzTSt6YAavYG6eW3n8PBB3SEX1yY5gE6FKhFJHdFLPn97vfu4u3C4ubHE4b35icjjk/3qKIoUItI7gotBV7b7RhGXPdI2FMb7hrpmyqTCtQikrsqKgi02LQCUDXnlwydPN5ZceYT/lyeJyKSYr9fujksSB/0RT3BmeOcIJ2mm4Re5VSgzsvLY9CgQc1/gsEgp53m1JcKBoM888wzzX2XLVvGggULYr1VTGeccYbrjceW7ftSGlVEPIhTfXN3QyOBSfO58fnlzW1v3zKcFfdfDsGg74I05Fjq44ADDmDZsmVhbW+++SawN1B///vOgvZly5ZRXV3NyJEjkz6OtvwAEBGP4iy567OmG7saGpu7fm/IMdx1qXvtHj/JqRm1m6ai/JMmTeL1119n0KBBTJs2jcmTJ/Pcc88xaNAgnnvuOT7//HOuvfZahgwZwoknnthcOnTXrl2MGTOGPn36cMkllzTX94jHS2nU9evXc9555zF48GC+9a1vsWbNmtT9RxDJJi5L7j7ofBiBmoKwIL2u4tsZEaShnWbUv/jjSlZ99FlS37Pv0V25/YJ+cfvs2rWrubpdz549mTNnTvNzU6dO5d5772XevHkAHHHEEVRXV/Ob3/wGgFtuuYWzzjqLJ598ktraWoYMGcLZZ5/NY489RufOnVm9ejXvvfceJ510UqvGvXbtWp599lkef/xxRo8ezezZs7niiisoKyvj0UcfpXfv3rz99tuMHTuWhQsXtuq9RXJSxJK7wMR5YY/HH76bGx+8Ce6O3onoVzmf+vDq5ZdfZu7cuc1HZ+3evZtNmzaxaNEixo8fD8CAAQNilkCNxa00al1dHW+++SaXX355c78vvkhPTQGRjBdacnfH8DJmlIRvUAkW18ZMi/g5WLdLoE408/Ujay2zZ8/mhBNOSOr7upVG3bNnDwUFBW3+oSKSUyJqdTSOHEmvrqPCuvz++XJOmnJz/ENJfByocz5H3SSyVGjk43PPPZeHHnqo+aSUd999F4Bhw4Y1rxZZsWIF77333j6PpWvXrvTs2ZMXXngBcH5ILF++PMGrRHJQxLF9gTHTo4J0cOY4J0iXlrbboST7SoE6ZMCAAeTl5TFw4EDuv/9+zjzzTFatWtV8M/G2226joaGBAQMG0K9fP2677TYAbrjhBurq6ujTpw+TJ0+OOu6rraqqqnjiiScYOHAg/fr107mHIm5CM+RgwVFRuehlk0cQnDoqfMldGg6iTQWVOc1h+p5IxuvQgcDP/hjW1Gv7P/nbE2Nhz57o/pFL9yDp5UrbSmVORSTr3LVgNY9FBOngtPOdL4qK3F/UFIxj1J/2K6U+RMS/Ypz8HZg0n8cWfdjcbfziZ/YG6UTH9pWWOumQPXt8uxMxUlpn1NZa31SjynWpSHmJJJXLDsNATQFEnLgSLK6FmYudIkoZMkNurbQF6vz8fLZv3063bt0UrNuZtZbt27eTn5/f3kMRia3FUrpPDjqUk8c9Hfb0X28cxnGHd3EeZFlgjpS2QN2jRw82b97Mtm3b0vWREkd+fj49evRo72GIxBZaMhe5mgNwVnPkkLQF6o4dO9KzZ890fZyI+F2cQ2UBHj73h9w98OKwl3w47QI6FBWCArWISIrFqXBHaSmBSfOhRZAe9uESnn7h9sQ3CrOUArWIpF+MrdxDF3/Jlpr5Yc3BmeOcWXeaT/72EwVqEUm/iC3bn3fMp9+Ns8LanrnuZE477rCcS3O4UaAWkfQLVbiDGDcLZ46DqcE0D8q/tOFFRNKvooIXB46ICtKrfnWZs3Fl48aYR2nlIs2oRSTtAjUFcN6E5scHfVHPil+P3tvBmOYZd6bUjE6lhIHaGHMC8FyLpmOBydbaX6dqUCKSnYZU/JWtO8MPwWje+t3EGIjcOZsBNaNTKWGgtta+DwwCMMbkAVuAOfFeIyLS0leNeziu/KWwtp+89RwTXvtteMdu3WD7dvc38XnN6FRqbepjOLDeWrsxFYMRkewTmDQ/qi04c9ze1EZLBx3k/HF7zuc1o1OptTcTxwDPpmIgIpJdlmz8T1SQfmPimc7273gnrVRUOBtbWsrRjS5NPM+ojTH7AxcCP4/xfBlQBlCYwz/5RCTGLLrleugWy/PCFBZmbM3oVPJ8wosx5iJgnLX2nER93U54EZHsd/1vl/Cnlf8Ka3MtoOTjk1baS7JOePkeSnuISAyRs+hz+h5B5ZWucUez5lbyNKM2xhwIbAKOtdbuSNRfM2qR3JEwzSGe7POM2lr7OdAtqaMSkYy2cfvnnH7Pq2Fts284jcFFh7TPgLKYdiaKSKu5zqKLa0FBOiUUqEXEszvmrmTGm8GwtnV3X8h+ds/eJXXKMyedArWIeOI6i265/TvHt3mnkqrnieS6qqq4leoCk+ZHBeng3RdE1+iAnN7mnUoK1CK5rGk988aNTiGkpkp1VVV8trshKkD/98X9nRUdsTa1abNbSij1IZLLYhyJFagpgJqXw5rDltxVVLhvWMnhbd6ppBm1SC5qSndEbON+vji6mP/yyedEr4suLXV2ERYVOWVJi4pyeldhqmlGLZJr3LZvE+NIrHgbV0pLFZjTRIFaJNdEpDtcA3RxrYKwjyj1IZJrQiszvjIdooL099e9riDtQ5pRi+SawkICY6ZHNQdnjoNgMP3jkYQ0oxbJZAnWQEd6Y+2nUUH6z0+MI/jQaK3Y8DHNqEUyVeRNwVindVdVQXm5+yz67guctc+/1ooNP/N8cEBrqMypSBq4LK8DnKVyTSmMqipOf303GwuODOuyoX8t5goFZj9J1sEBIuIn8c4dDAnUFEDB3qcOqd/Buw+VOsFcgTpjKFCLZKo45w4mLKCkmhwZRTcTRTKVy2nd677WOyoXXTl7SnQBJdXkyCiaUYtkqohzBwM/+2NUl2BxLTxUE96omhwZR4FaxO9CqzZcD4EtLeW6r07gr6s/CXvJ+/99Hp32y9vboENkM5oCtYifJViC5+lgWdXkyHjKUYv4WZwypFHF/KeOcoJ0KzfBiP9pRi3iZxGrM3Z0OpCB//VcWFvZsGO5ZWQf54HXTTCSUbThRcTPWmxq8VSG1MsmGPGleBtelPoQ8ZuWqYu6Ou47/cqoIP2Pr+9wrxXtYROMZB6lPkT8JCJ1EbjuqaguccuQxtkEI5lLgVrET0I3D1t92koTnWWYlZT6EPGRxn9ujgrShf/52Kly54XOMsxKupko4hNx63PoZmDWU/U8ER979f2tXP2/74S1zfrdzZRsWe08UOoi5ylQi7SjmLPovND276IibfkWBWqR9jDoly9TW98Q1rbhodGYppuAjY17Z9IK0jnP081EY0yBMWaWMWaNMWa1MebUVA9MJFsFJs2PCtLBmeP2Bukm9fXOKhDJeV5n1A8Af7LWfscYsz/QOdELRCRc3AJKsVZ1aKOK4CFQG2MOBoYBVwNYa78EvkztsESyx4fb6jjrvtfC2u67fCCXDe6xt0EbVSQOLzPqnsA24H+NMQOBJcAEa+3nLTsZY8qAMoBC/eMSARLMolvSRhWJw0uOej/gJOARa+2JwOfApMhO1tpKa22Jtbake/fuSR6miI+5lBUd98zSqCC9Zsp5sXcXaqOKxOFlRr0Z2GytfTv0eBYugVokJ7mUFQ3UFAAfh3XztP1bBf4lhoSB2lr7L2PMP40xJ1hr3weGA6tSPzSRDNCisH+b63OIJOC11sePgSpjzHvAIODOlI1IJJNs2sSOTgdGBelrql9UkJak8bQ8z1q7DHDdgy6Sy1xP/p52vpNjFkkS7UwUaYMH/7aWX/3lg7C2xQ9fw9d2btNqDUk6BWqRVnJdcjdzHNR9qtockhIK1CIexV0TrXy0pJAODhBJoHGPjQrSh3fppJuFkjYK1JKbXDapuAlMmk+vWxaEtQWnjuIf5WenfowiIUp9SO4ZOxYefRSaTjfauNHZtALNueWFaz7h2hnhpxTNLDuFU47tls6RigAK1JJrxo6FRx6Jbm8qKVpa6r0+h0iaKFBL7qiqcmbSMfQa/SCNEUF6w10jMcakemQicSlQS+4oL9+b7oig7d/iZwrUkjtcivArQEsm0KoPyR2HHtr85bpuPaKC9B0X9FWQFl/SjFpyQ1UV7NwJaBYtmUeBWnJDeTmll0xmcWBQWPPKGWUc+K8t7TMmEY+U+pDsFLGhJTBmelSQDk47nwO3fuz6chE/0Yxask+LU1dc0xzTzt/7QOd7SgbQjFqyT3k5O7+yUUF6xNq3woO0ypFKhtCMWrJOYMz0qLbmAF1U5CzTKyxUOVLJGArUkjUe+tta7oso5v/aY9dRVPsv50FREQSD6R+YyD5SoJas4FqfQ2kOyRIK1JLRYhZQqqpSmkOyhgK1ZKQ9eyzHRtSJ7phnWFsx0nlQWqrALFlDgVoyjsqQSq5RoJaM8cqarVwz452wtqeuHcLpx3dvpxGJpIfWUUtGCEyaHxWkgzPHcfrXj4h7lJZINtCMWnzNLc2xoX8t5v85Ow8B16O0RLKJZtSSGh4Pj40nVi7a3Fq+N0g3aTpKSyQLaUYtydei1gbQ6hlvwpuFLgcAxG0XyXCaUUvylbdtxhv89POoIH3zuSdEr+iIVUhJBZYkS2lGLcnXhhlvq5bcVVSEz9hBOw8lqylQS/IVFjrpDrf2CNfOeIeFa7aGta34xbkc1CnOP82m9El5uXYeSk5QoJbk8zjj3aeNK9p5KDnEU6A2xgSBnUAj8JW1tiSVg5IMl2DGq52FIq3Tmhn1mdbaT1M2EskuLjPez7/4in63/zmsbdjx3Xn62iHpHJlIxlHqQ9JCs2iRtvMaqC3wsjHGAo9ZaysjOxhjyoAygEItk5KQx15bz10vrQlrW3jT6Rzb/aB2GpFI5vEaqL9prd1ijDkc+IsxZo21dlHLDqHgXQlQUlJikzxOyUCaRYskh6dAba3dEvp7qzFmDjAEWBT/VZKrFKBFkivhzkRjzIHGmC5NXwPnACtSPTDJPNZa9yA9c5yq24nsAy8z6iOAOcaYpv7PWGv/lNJRScZJeGahqtuJtFnCQG2t/RAYmIaxSAZauOYTrp1RHdb2yBuP8+3FL4Z3bKr1oUAt0mpanidtFjMXbc536Y2q24m0kQK1tJpbgP7wzpF06GCcXLQxYF0W/mjZpkibKFBLqyRc0VFe7h6kjVF1O5E2UqAWTzwvuYuV3rBW+WmRNtLBARKtxTFawf7fiArSZcOOjb0uOlZ6o6gouWMUySGaUeeyqqroCnfQXKI0MHFe1EsSblxRUX+RpFOgzlWxzjU84ABKL7iFxYFBYd2Xz/4pB69dnfh9VdRfJOkUqHOB28w5xrmGgR8/H/Xy4LTznZuBXqmov0hSKVBnu1gz54gg7ZrmaLmzUEvrRNqNbiZmuwkT3E8Ez8tzvuzYKSpI99m6ITxIK8cs0q40o85mVVWwfbv7c42NsWfR3bo5qzSUYxbxBQXqbFZe7to8/ZTLuef0q8LaXnry/9NnW9B58O9/w6c6dU3ELxSos5nL5pOEuWhQPlrEZxSos1lhoXPzkBgBurh2b/nRJspHi/iObiZms4oKbOfOsTeulJZCZaWTjzbG+buyUvloEZ8x1q2Azj4qKSmx1dXViTtKSrnW5yiuVSAW8SFjzBJrbYnbc0p9ZKG/r9/O9x5/K6zt0StO4rz+R7XTiERkXyhQZxkdLCuSfRSos8SJv3yZ/9Q3hLWtv3MkeR1asfVbRHxJgToLaBYtkt0UqDOYa4CeOU7L60SyjJbnZaAttbuigvTYvz/vbFxpKrpUVdVOoxORZNOM2k8iy5GOHAkLFoTV3AjUFES9LGpnYX298z5ahieSFRSo/cKtHOkjjzQ/PaH4cl6MCNLLJo+g4KB89/eLdXahiGQcBWq/cCvkHxL3SKwW28TDqF6HSNZQoPYLrwWU7r4A9uzZ26AzCkWynm4m+kWLGfDuvI5RQXrgR+87uejImbLqdYhkPc2o/SI0M455ZiHEninrjEKRrKYZtU+8cMKwqCD917rXnHXRmimL5DTNqH0g9s7CUfCbu9M/IBHxFc+B2hiTB1QDW6y15yfqL4lp67eIeNGa1McEYHWqBpJLrLVRQbqDUZAWEXeeArUxpgcwCvif1A4nC1RVQSAAHTo4f0ds5Q5Mmk/Pny8IawtOHcWHdylIi4g7r6mPXwM/A7rE6mCMKQPKAApzdbOF2+7C0JmEy4aN4uLpi8O6P35lCSP6HpHuUYpIhkkYqI0x5wNbrbVLjDFnxOpnra0EKsE5iitZA8wobrsL6+ud+hw14UFaaQ4R8crLjHoocKExZiSQD3Q1xvzOWntFaoeWgSJ2F468+gFWHdErrG1dxbfZL0+rIkXEu4QRw1r7c2ttD2ttABgDLFSQjqFFyicwcV5UkA5OHaUgLSKtpnXUyRSrDKlO/haRfdCq6Z219tWcW0OdYBVHk0/rvogK0hPeeIbg/1yV8iGKSHbTjDqeOKs4Ws6QXTeutCzm7/IaERGvjLXJX6BRUlJiq6urk/6+aRcIuNd6Bigq4v7x9/HA1vDC/ctn/5SD161x7U8wmPQhikh2MMYssdaWuD2nGXU8cU5JCYyZDlvD24JTR8HdF7T6vURE4lGgjsfl9JS4p63EeE1zu4hIG2itWDwVFU4NaKChQ15UkB615nXnxJUYr2mmE1dEZB9oRh1P6OZf3JO/i4pcXxN2mnhFhW4kikibKVDH8cr7W7kmIki/+tiPCNR+7DzQiSsikgYK1DG4LrkrroWD94cdRjNlEUkbBeoI333s77y94d9hbWE3CxWYRSTNFKhbiJxF9zu6K/PHf6udRiMi4lCgRkdiiYi/5XSg3rj9c06/59WwtlnXn0pJ4ND2GZCIiIucXUcdmDQ/KkgHp45ygrTHQkwiIumQczPqOxespnLRh2Ft6+8cSV4H4zzwWIhJRCRdcqooU2Qu+sD981j5y/MiOgXct4CrqJKIpFDOF2Vq1c3CWMWTVFRJRNpJVueoP9vdEBWk77t8YPwVHbGKJ6mokoi0k8wL1B5v9AUmzWfAHS+HtQWnjuKywT3iv7+KKomIz2RW6sPDjb4/rfgX1/9uSdjL3rvjHLrmd/T2GSqqJCI+k1k3ExPc6NPGFRHJVPFuJmZW6iPGDb3zzvppVJAOzhzn1IrWOmgRyXCZFagjbug1mg4EJs5jzeE9m9smHbmL4EOjnZm3tXvTIwrWIpKh/BeoI28Wjh2793FdHXR0cs2BifPo9bO5YS8NTh3F9b/+6d4cdpP6eifnLCKSgfx1M9HtZuEjj+x9fvt21h55LCOuejDsZW9OOoujCw5wHmgdtIhkGf8E6qoquOoqaGyM2SXhwbKgw2VFJOv4I/XRNJOOEaTv+9YVUUE6OHWU+4oOrYMWkSzjj0BdXh6dVw4JTJzHQ6eNaX58/VsvEJw5LvZ7lZZCZaWzZM8Y5+/KSq2DFpGM5Y/Uh0v++CejbmRO/7PC2oLTzndmx5WV8d9Ph8uKSBbxR6BukVdu6JBH75tfDHv61Xl3EFi1xJkda5egiOQYf6Q+QnnluX2GhQXpgVvXE7z7AgJ12+C3v3XKjCpIi0iO8ceMOhR8x9cUAHD2xnd5/PdTMF9+6Tyv4v0iksMS1vowxuQDi4BOOIF9lrX29nivaWutj3/+u55Oc//A4ddd6b4CRMX7RSRL7evBAV8AZ1lr64wxHYE3jDEvWWvfSuoogWNemgPjYi/T06YVEclFCQO1dabcdaGHHUN/kl9yD+Iu0wO0aUVEcpKnm4nGmDxjzDJgK/AXa+3bLn3KjDHVxpjqbdu2tW008WbM2rQiIjnKU6C21jZaawcBPYAhxpj+Ln0qrbUl1tqS7t27t200sWbMeXnatCIiOatVy/OstbXAK8B5Cbq2Tazt3089pSAtIjkrYaA2xnQ3xhSEvj4AGAGsSclotP1bRCSKl1UfRwFPGWPycAL789ba6DJ2yaLt3yIiYbys+ngPODENYxERERf+2EIuIiIxKVCLiPicArWIiM8pUIuI+FzCokxtelNjtgEuBxc2Owz4NOkfnBly9dpz9bohd689V68b2nbtRdZa192CKQnUiRhjqmNVicp2uXrtuXrdkLvXnqvXDcm/dqU+RER8ToFaRMTn2itQJzidNqvl6rXn6nVD7l57rl43JPna2yVHLSIi3in1ISLicwrUIiI+l9JAbYw5zxjzvjFmnTFmksvznYwxz4Wef9sYE0jleNLFw3XfaIxZZYx5zxjzN2NMUXuMMxUSXXuLfpcZY6wxJmuWb3m5dmPM6ND3fqUx5pl0jzEVPPx7LzTGvGKMeTf0b35ke4wz2YwxTxpjthpjVsR43hhjHgz9d3nPGHNSmz/MWpuSP0AesB44FtgfWA70jegzFng09PUY4LlUjSddfzxe95lA59DXN2TDdXu99lC/Ljgn278FlLT3uNP4fe8NvAscEnp8eHuPO03XXQncEPq6LxBs73En6dqHAScBK2I8PxJ4CTDAKcDbbf2sVM6ohwDrrLUfWmu/BGYCF0X0uQh4KvT1LGC4McakcEzpkPC6rbWvWGubTvF9C+eIs2zg5XsOMAWYBuxO5+BSzMu1/wiYbq39D4C1dmuax5gKXq7bAl1DXx8MfJTG8aWMtXYR8O84XS4CnraOt4ACY8xRbfmsVAbqrwH/bPF4c6jNtY+19itgB9AthWNKBy/X3dIPcX7qZoOE1x769e8Ya+38dA4sDbx8348HjjfGLDbGvGWMSc2Rdunl5brvAK4wxmwGFgA/Ts/Q2l1rY0FMXk54kRQxxlwBlACnt/dY0sEY0wH4FXB1Ow+lveyHk/44A+e3qEXGmGLrnEWazb4HzLDW3meMORX4rTGmv7V2T3sPLFOkcka9BTimxeMeoTbXPsaY/XB+LdqewjGlg5frxhhzNlAOXGit/SJNY0u1RNfeBegPvGqMCeLk7eZmyQ1FL9/3zcBca22DtXYD8AFO4M5kXq77h8DzANbavwP5OEWLsp2nWOBFKgP1O0BvY0xPY8z+ODcL50b0mQtcFfr6O8BCG8rCZ7CE122MORF4DCdIZ0Oesknca7fW7rDWHmatDVhrAzj5+QuttdXtM9yk8vLv/Q84s2mMMYfhpEI+TOMYU8HLdW8ChgMYY/rgBOptaR1l+5gLXBla/XEKsMNa+3Gb3inFd0VH4swa1gPlobZf4vzPCc437AVgHfAP4Nj2vpObpuv+K/AJsCz0Z257jzld1x7R91WyZNWHx++7wUn9rAJqgDHtPeY0XXdfYDHOipBlwDntPeYkXfezwMdAA85vSz8Ergeub/H9nh7671KzL//WtYVcRMTntDNRRMTnFKhFRHxOgVpExOcUqEVEfE6BWkTE5xSoRUR8ToFaRMTn/g+b0VUH/FFqfAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.7749361991882324 s\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Parameters\n",
    "learning_rate = 10\n",
    "training_epochs = 60\n",
    "display_step = 100\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(np.random.randn(), name = \"weight\")\n",
    "b = tf.Variable(np.random.randn(), name = \"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * n_samples)\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "start = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x, y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict = {X: x, Y: y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(c), \n",
    "                \"W =\", sess.run(W), \"b =\", sess.run(b))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print (\"Training cost =\", training_cost, \"W =\", sess.run(W), \" b=\", sess.run(b), '\\n')\n",
    "    \n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "end = time.time()\n",
    "t = (end - start)\n",
    "print('Execution time:', t, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Những nhận xét đánh giá của sinh viên*:\n",
    "\n",
    "Sau khi chạy thử và tính toán thời gian thực thi với nhiều bộ số Learning rate và Epoch, ta có các kết quả tiêu biểu về thời gian thực thi và tính phù hợp của mô hình như sau:\n",
    "\n",
    "    - Learning rate: 0.01, Epoch: 1000 --> 28.91 s, fit không tốt\n",
    "    \n",
    "    - Learning rate: 0.01, Epoch: 1300 --> 34.51 s, fit không tốt\n",
    "    \n",
    "    - Learning rate: 0.01, Epoch: 1700 --> 53.35 s, fit không tốt\n",
    "    \n",
    "    - Learning rate: 0.1, Epoch: 1000 --> 24.03 s, fit tốt\n",
    "    \n",
    "    - Learning rate: 0.5, Epoch: 1000 --> 22.01 s, fit tốt\n",
    "    \n",
    "    - Learning rate: 1, Epoch: 1000 --> 25.17 s, fit tốt\n",
    "    \n",
    "    - Learning rate: 2, Epoch: 200 --> 6.16 s, fit tốt\n",
    "    \n",
    "    - Learning rate: 8, Epoch: 100 --> 2.35 s, fit tốt\n",
    "    \n",
    "    - Learning rate: 10, Epoch: 60 --> 2.12 s, fit tốt\n",
    "    \n",
    "    \n",
    "Với bộ số Learning rate = 10 và Epoch = 60, nếu chúng ta tiếp tục từ từ tăng Learning rate và giảm Epoch, các kết quả thu được (về cả thời gian thực thi và mức độ phù hợp của mô hình) đa phần sẽ không khác biệt nhiều lắm với kết quả thu được hiện tại (tuy nhiên không tăng Learning rate quá mức hay giảm Epoch quá nhỏ vì khi đó thuật toán Gradient Descent sẽ thực hiện không chính xác, không tìm được cực tiểu cũng như không xác định được mô hình).\n",
    "\n",
    "Vậy có thể kết luận bộ tham số Learning rate = 10 và Epoch = 60 có thể được coi là một trong những bộ tham số cho ra kết quả \"gần như\" là tốt nhất."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f335e8124b1c62b05d32949df1cccc2b33e317e0a1d5d1d25878ac9a5759686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
